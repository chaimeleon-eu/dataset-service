
db:    # The parameters needed to access to a Postgres database service that must be running.
  host: "localhost"
  port: "5432"
  dbname: "db"
  user: "dssuser"
  password: "XXXXXX"

auth:
  token_validation:   # These are the parameters for the validation of auth tokens received from user requests.
    token_issuer_public_keys_url: "https://chaimeleon-eu.i3m.upv.es/auth/realms/CHAIMELEON/protocol/openid-connect/certs"
      # The URL to the public keys of the authentication service that issue the tokens.
    kid: "U2yU60He9Irc8iNJ7zCBVUQEkXe9yq0XrHLu4f3i1gT"
      # The key ID (kid) is just for selecting which key have to be downloaded from the token_issuer_public_keys_url in the 
      # initialization in order to validate later the coming tokens. 
      # Usually there is only one key, so just go to the URL and copy the kid.
    client_id: "dataset-service"
      # This used for the accepted value in the "audience" claim,
      # but also for the key to retrive from "resource_access" claim, which contains the user's roles for this application.
      # You should write here the client ID configured in the authentication service for this application (the dataset-service).
    issuer: "https://chaimeleon-eu.i3m.upv.es/auth/realms/CHAIMELEON"
      # The accepted value for the "issuer" claim.
    roles:   # Here you can customize the string that defines every role appearing in the token to allow the user to do things.
      use_datasets: "use_datasets"
      admin_datasets: "admin_datasets"
      superadmin_datasets: "superadmin_datasets"
      admin_users: "admin_users"
      admin_datasetAccess: "admin_datasetAccess"
      admin_projects: "admin_projects"
    project_group_prefix: "PROJECT-"
    project_admins_group_prefix: "ADMINS-PROJECT-"
  client:   # These are the parameters for login (get an auth token) as a service account in the auth service, 
            # in order to access other services like tracer or the keycloak admin API.
    auth_url: "https://chaimeleon-eu.i3m.upv.es/auth/realms/CHAIMELEON/protocol/openid-connect/token"
      # The url of authentication service.
    client_id: "dataset-service"
      # The client id of the dataset-service in the authentication service (it is like the "username" of a service account).
    client_secret: "XXXXXXXXXXXXXXXXXXXXXXX"
      # The client secret of the dataset-service client (it is like the "password" when login as a service account).
  admin_api:
    url: "https://chaimeleon-eu.i3m.upv.es/auth/admin/realms/CHAIMELEON/"
      # The URL to the authentication admin api, for querying user groups, manage users, create projects as groups.
      # Please note the auth.client params will be used to access to this service (authentication admin).
      # Also note that the following roles must be added to the service account roles 
      # (and also in the "dedicated scope" of the client if "full scope" is not enabled): 
      #   "realm-management/query-groups", "realm-management/query-users", 
      #   "realm-management/view-users", "realm-management/view-clients".
    client_id_to_request_user_tokens: "dataset-explorer"
      # The id of the public client used to get user tokens (impersonation).
      # This is when the caller is trusted (e.j: the k8s operator), it uses a service account to authenticate itself,
      # but a user token is required for the operation (i.e to check the access of a user to a dataset: 
      # the user token is required to obtain the roles and projects). So the token will be get for that user in that client.
    parent_group_of_project_groups: "/PROJECTS"
      # Whener a new project is created, a new group will be automatically created in the auth service within this parent group.
      # That way, when a user is joined to a project, in fact it is added to the group, 
      # and so that group will appear in the user's auth token.
      # The group name will be the project code prefixed with auth.token_validation.project_group_prefix.
      # You can set this parameter to empty string to not create automatically a group in the auth service for each new project 
      # (if you prefer to do it manually).
  user_management:
    prefix_for_roles_as_groups: "/"
    prefix_for_projects_as_groups: "/PROJECTS/PROJECT-"
    assignable_general_roles: ["application-developer", "authorized-technical-data-manager", "clinical-staff", 
                               "cloud-services-and-security-management", "data-scientists", "dataset-administrator"]

tracer:
  url: "https://chaimeleon-eu.i3m.upv.es/tracer-service/tracer/"
    # The url of the tracer service for notifying dataset events. 
    # You can set it to empty to disable the notification to tracer.
    # Please note the auth.client params will be used for getting the token to access to this service.

zenodo:
  url: "https://sandbox.zenodo.org/"
    # The url of Zenodo service to submit depositions.
    # Usually "https://sandbox.zenodo.org/" for testing, and "https://zenodo.org/" for production.
    # The account used to access and create depositions in Zenodo is configured per project in the project configuration 
    # set by PUT "/projects/<code>/config".

on_event_scripts:
  user_management_job_template_file_path: ""
    # You can set it to launch a k8s job running a script whenever a user is created (received PUT /users/<userName>)
    # to create the user in other services of the platform or make some configurations related to the new user.
    # Example: "/var/on-event-jobs/user-management-job-template.private.yaml"
    # Set it to empty string to disable that feature.
  site_management_job_template_file_path: ""
    # You can set it to launch a k8s job running a script whenever a site is created or updated (received PUT /sites/<code>)
    # to create the site in other services of the platform or make some configurations related to the new site.
    # Example: "/var/on-event-jobs/site-management-job-template.private.yaml"
    # Set it to empty string to disable that feature.
  subproject_management_job_template_file_path: ""
    # You can set it to launch a k8s job running a script whenever a subproject is created or updated 
    # (received PUT /projects/<code>/subprojects/<subcode>) to create the subproject in other services of the platform 
    # or make some configurations related to the new subproject.
    # Example: "/var/on-event-jobs/subproject-management-job-template.private.yaml"
    # Set it to empty string to disable that feature.

logos:  # These are the parameters for logos management (currently logos for projects)
  image_size_px: 500
    # The logo images will be resized to image_size_px X image_size_px (but preserving aspect ratio) and then stored in PNG format.
  max_upload_file_size_mb: 8
    # The limit of file size to be uploaded to set the logo.

self: 
  name: "dataset-service"
  host: "0.0.0.0"
  port: 11000
  root_url: "https://chaimeleon-eu.i3m.upv.es/dataset-service"
    # The root url were that service will be exposed.
    # It is used to build some urls returned by some operations (like the logo url in the details of a project).
  log: 
    main_service:
        level: "DEBUG"
          # Possible levels from the most to the minimum verbose: DEBUG, INFO, WARN, ERROR, FATAL.
        file_path: "/dataset-service/log/dataset-service.log"
          # Destination file path.
        max_size: 10485760
          # Max size of file in bytes. When it get the max size it is closed and renamed appending ".1".
          # If the file ending with ".1" already exists, it is renamed to ".2", and so on until the max backup of 3.
    dataset_creation_job:
        level: "DEBUG"
        file_path: "/dataset-service/log/dataset-creation-job-%s.log"
          # In this case '%s' will be replaced by the dataset id.
        max_size: 10485760
  static_api_doc_dir_path: "/var/www/api-doc"
    # Absolute directory path where the API reference documentation is (an index.html file should be there).
    # It will be served when a request of path "/api-doc" is received.
  static_files_dir_path: "/var/www/dataset-service-ui"
    # Absolute directory path where the web UI static files are.
    # They will be served when a request of root path ("/") or "/web/..." is received.
  static_files_logos_dir_path: "/var/www/project-logos"
    # Absolute directory path where the logos static image files are.
    # They will be served when a request of path "/project-logos/..." is received.
  static_files_output_dir_path: "/var/www/output-files"
    # Absolute directory path where the output static files are deposited to download.
    # They will be served when a request of path "/output-files/..." is received.
  dev_token: ""
    # Secret token for the POST "/api/set-ui" operation (for developers, to set the web UI static files).
    # If empty token, that operation is not allowed (404 returned), this way you can disable it.
  datalakeinfo_dir_path: "/var/www/datalakeinfo"
  datalakeinfo_token: ""
    # Secret token for the GET "/datalakeinfo" operation (for auditors, to get some statistics of datalake).
    # If empty token, that operation is not allowed (404 returned), this way you can disable it.
  datalake_mount_path: "/mnt/datalake"
  datasets_mount_path: "/mnt/datasets"
  datalake_external_subpath: "0-EXTERNAL-DATA"
    # It is a directory within datalake, where the external datasets should be transferred.
    # The files transferred should be organized in directories like: 
    # datalake_mount_path/datalake_external_subpath/dataset_name/subject_name/study_name/series_name/images
    # Once the transference ends, an admin user should request a POST /api/datasets?external=true,
    # and so an external dataset is created in the database and in datasets_mount_path, 
    # and the studies there will be symbolic links to the transferred files in datalake_external_subpath.
  external_datasets_project_code: "EXTERNAL-DATASETS"
    # It is a special project code assigned to external datasets. 
    # The project does not exist (and the code is reserved, can not be used to create a new project).
    # WARNING: Don't change if there is any external dataset already created, it will not be updated to the new project code. 
  eforms_file_name: "eforms.json"
  index_file_name: "index.json"
  studies_tmp_file_name: ".studies.json"
  dataset_link_format: "https://chaimeleon-eu.i3m.upv.es/dataset-service/datasets/%s/details"
    # Url format of public available details of a dataset (using the endpoint of the WebUI, the Dataset-explorer)
    # It is used for the url returned in the dataset creation POST, 
    # and also for the links included in the publication submited to Zenodo.
  eucaim_search_token: ""
    # Secret token for the POST "/api/datasets/eucaimSearch" operation (custom search for EUCAIM project).
    # If empty token, that operation is not allowed (404 returned), this way you can disable it.
  eucaim_search_filter_by_tag: ""
    # By default only published and not invalidated datasets are returned to the EUCAIM search, 
    # but additionaly you can filter by any tag.
    # Example: "eucaim-indexed" (only datasets published, not invalidated and with that tag will be included in search results).
    # Set it to empty string to disable this extra filter.
  series_hash_cache_life_days: 30
    # Time span to avoid read again all the files of a series to calculate the hash.
    # It is very useful during a global integrity check when there are different datasets containing the same studies/series. 
    # The hash of each series will be calculated only one time.
    # And during the creation of a dataset when some of its studies are the same as in another datasets lately created.
    # Even during a relaunch of a dataset creation process if it has been interrupted 
    # (the process will be resumed because the hash of first studies/series will already be calculated and cached).
  dataset_integrity_check_life_days: 40
    # Time span to not repeat the integrity check of a dataset if already checked recently.
    # This is also useful for resume a previous interrupted global check.
    # NOTE: this life days should be greather than series_hash_cache_life_days, 
    #       otherwise the integrity check will take the cached series hashes.
    